{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guardyourheart/gladiator/blob/main/gladiator_auto111_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öîÔ∏è Gladiator WebUI"
      ],
      "metadata": {
        "id": "5N8XFfYO1Wth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #STEP 1Ô∏è‚É£: Download Gladiator WebUI and req\n",
        "from IPython.display import clear_output, display, HTML\n",
        "import time\n",
        "import subprocess\n",
        "import shutil\n",
        "import requests\n",
        "import urllib.request\n",
        "import threading\n",
        "from datetime import timedelta\n",
        "from google.colab import drive\n",
        "from IPython.utils import capture\n",
        "from subprocess import getoutput\n",
        "from urllib.parse import unquote\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "def check_gpu():\n",
        "    print(\"\\033[96m\")  # Cyan text\n",
        "    print('‚åö Checking GPU...', end='')\n",
        "    output = getoutput('nvidia-smi --query-gpu=gpu_name --format=csv')\n",
        "    if \"name\" in output:\n",
        "        gpu_name = output[5:]\n",
        "        print('\\r‚úÖ Current GPU:', gpu_name, flush=True)\n",
        "    else:\n",
        "        print('\\r\\033[91m‚ùé ERROR: No GPU detected. Lakukan Step dibawah ini.\\n', flush=True)\n",
        "        # Additional code for displaying an image and message\n",
        "        display(HTML(\"<img src='https://i.ibb.co/HC9KH17/NVIDIA-Share-23-01-02-173037.png' width='800px'/>\"))\n",
        "        print('\\033[91m\\nJika tertulis \"Cannot connect to GPU backend\", berarti telah mencapai batas pemakaian. Silahakn istirahat untuk hari ini...')\n",
        "        display(HTML(\"<center><img src='https://media.tenor.com/RY9NX67klacAAAAi/sad-cute.gif' width='272px'/></center>\"))\n",
        "        time.sleep(5)\n",
        "        from google.colab import runtime\n",
        "        runtime.unassign()\n",
        "\n",
        "def clone_repositories():\n",
        "    SD_Next_Commit_Hash = \"last commit\"  # @param {'type': 'string'}\n",
        "    #@markdown Leave this if you want lastest version of Stable Diffusion.\n",
        "    if SD_Next_Commit_Hash == \"last commit\":\n",
        "        subprocess.run([\"git\", \"clone\", \"--depth=1\", \"https://github.com/guardyourheart/gladiator_webui.git\"])\n",
        "    else:\n",
        "        subprocess.run([\"git\", \"clone\", \"https://github.com/guardyourheart/gladiator_webui.git\"])\n",
        "        subprocess.run([\"git\", \"checkout\", SD_Next_Commit_Hash], cwd=\"gladiator_webui\")\n",
        "\n",
        "    !git clone https://github.com/guardyourheart/gladiator_webui.git\n",
        "    clear_output()\n",
        "\n",
        "def install_requirements():\n",
        "    %cd /content/gladiator_webui\n",
        "    !pip install --use-feature=fast-deps -r requirements.txt\n",
        "    !pip install -q torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 torchtext==0.15.2 torchdata==0.6.1 --extra-index-url https://download.pytorch.org/whl/cu118 -U\n",
        "    !pip install -q xformers==0.0.20 triton==2.1.0 gradio-client -U\n",
        "    !pip install --upgrade huggingface_hub\n",
        "    !pip install wget\n",
        "    !apt -y install -qq aria2 libcairo2-dev pkg-config python3-dev\n",
        "    clear_output()\n",
        "\n",
        "def clone_MiDaS():\n",
        "    %cd /content/gladiator_webui/repositories\n",
        "    !git clone https://github.com/isl-org/MiDaS MiDaS\n",
        "    clear_output()\n",
        "\n",
        "def install_jemalloc():\n",
        "    %cd /content/gladiator_webui/\n",
        "    !apt -y update -qq\n",
        "    !apt -y install libjemalloc-dev\n",
        "    %env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2\n",
        "    clear_output()\n",
        "\n",
        "def connect_to_drive():\n",
        "    %cd /content\n",
        "    drive.mount('/content/drive')\n",
        "    clear_output()\n",
        "\n",
        "# Check GPU\n",
        "start_colab = int(time.time()) - 5\n",
        "check_gpu()\n",
        "\n",
        "connect_to_drive()\n",
        "\n",
        "# Clone repositories\n",
        "clone_repositories()\n",
        "\n",
        "# Pip Install Req\n",
        "install_requirements()\n",
        "\n",
        "# Install jemalloc and its development package\n",
        "install_jemalloc()\n",
        "\n",
        "%cd /content/gladiator_webui\n",
        "!git show --oneline -s\n",
        "print(\"‚úÖ Done\", \"success\")"
      ],
      "metadata": {
        "id": "U8eOMHN0sCQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üôà Download Models, Loras etc"
      ],
      "metadata": {
        "id": "uwtc9vu8zvj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Optionalüß©: Select mode vea or somthing else.\n",
        "\n",
        "def download_model(Type, DirectLink_URL):\n",
        "    if Type == \"None\" or not DirectLink_URL:\n",
        "        print(\"Skipping download as no valid Type or DirectLink_URL provided.\")\n",
        "        return\n",
        "\n",
        "    output_path = \"/content/gladiator_webui/models/\"\n",
        "\n",
        "    if Type == \"Checkpoint\":\n",
        "        output_path += \"Stable-diffusion/\"\n",
        "    elif Type == \"LoRA\":\n",
        "        output_path += \"LyCORIS/\"\n",
        "    elif Type == \"LoCon/LyCORIS\":\n",
        "        output_path += \"LyCORIS/\"\n",
        "    elif Type == \"Textual Inversion\":\n",
        "        output_path += \"embeddings/\"\n",
        "    else:\n",
        "        print(\"Invalid type specified.\")\n",
        "        return\n",
        "\n",
        "    # Create the directories if they don't exist\n",
        "    os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "    urls = [url.strip() for url in DirectLink_URL.split(\",\")]\n",
        "\n",
        "    for url in urls:\n",
        "        response = requests.get(url, stream=True)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            content_disposition = response.headers.get('content-disposition')\n",
        "            if content_disposition:\n",
        "                filename = unquote(content_disposition.split('filename=')[1])\n",
        "            else:\n",
        "                filename = unquote(url.split(\"/\")[-1])  # Extracting the filename from the URL\n",
        "\n",
        "            # Remove double quotes and semicolons from the filename\n",
        "            filename = filename.replace('\"', '').replace(';', '')\n",
        "\n",
        "            filename = os.path.join(output_path, filename)  # Modify the filename to include the output path\n",
        "\n",
        "            if not os.path.exists(filename):\n",
        "                print(\"Downloading file:\", filename)\n",
        "                chunk_size = 5242880  # 5 MB\n",
        "                with open(filename, 'wb') as f:\n",
        "                    for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                        if chunk:\n",
        "                            f.write(chunk)\n",
        "                print(\"File downloaded successfully.\")\n",
        "            else:\n",
        "                print(\"File already exists:\", filename)\n",
        "        else:\n",
        "            print(\"Failed to download the file:\", url)\n",
        "\n",
        "    # Clear the output to keep the notebook clean\n",
        "    clear_output()\n",
        "\n",
        "    # Print the success message\n",
        "    print(\"‚úÖ Done\", \"success\")\n",
        "\n",
        "# Call the function with the first set of parameters\n",
        "Type1 = \"Checkpoint\"  # @param [\"None\", \"Checkpoint\", \"LoRA\", \"LoCon/LyCORIS\", \"Textual Inversion\"]\n",
        "DirectLink_URL1 = \"https://civitai.com/api/download/models/152076, https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors\"  # @param {'type': 'string'}\n",
        "download_model(Type1, DirectLink_URL1)\n",
        "\n",
        "# Call the function with the second set of parameters\n",
        "Type2 = \"None\"  # @param [\"None\", \"Checkpoint\", \"LoRA\", \"LoCon/LyCORIS\", \"Textual Inversion\"]\n",
        "DirectLink_URL2 = \"\"  # @param {'type': 'string'}\n",
        "download_model(Type2, DirectLink_URL2)"
      ],
      "metadata": {
        "id": "hQuIZJ2_osnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üëªDownload Extensions, ControlNet, VEA, Upscalers\n"
      ],
      "metadata": {
        "id": "uLkmpa1_99LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #üé≤ Pre-Install Extensions\n",
        "\n",
        "!git clone https://github.com/camenduru/sd-civitai-browser /content/gladiator_webui/extensions/sd-civitai-browser\n",
        "!git clone https://github.com/guardyourheart/gladiator-webui-controlnet /content/gladiator_webui/extensions/gladiator-webui-controlnet\n",
        "!git clone https://github.com/guardyourheart/sdxl_aspect_ration /content/gladiator_webui/extensions/sdxl_aspect_ration\n",
        "!git clone https://github.com/nolanaatama/microsoftexcel-tunnels /content/gladiator_webui/extensions/microsoftexcel-tunnels\n",
        "!git clone https://github.com/Bing-su/adetailer /content/gladiator_webui/extensions/adetailer\n",
        "!git clone https://huggingface.co/Bingsu/adetailer /content/gladiator_webui/models/adetailer\n",
        "!git clone https://github.com/fkunn1326/openpose-editor /content/gladiator_webui/extensions/openpose-editor\n",
        "!git clone https://github.com/etherealxx/batchlinks-webui /content/gladiator_webui/extensions/batchlinks-webui\n",
        "!git clone https://github.com/Coyote-A/ultimate-upscale-for-automatic1111 /content/gladiator_webui/extensions/ultimate-upscale-for-automatic1111\n",
        "\n",
        "clear_output()\n",
        "print(\"‚úÖ Done\", \"success\")\n"
      ],
      "metadata": {
        "id": "41nGRTen2fSG",
        "outputId": "9a7d0f4c-4e4b-4da9-ac66-03f40c96609e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b9F3vRe3VzE",
        "cellView": "form",
        "outputId": "9454c027-ba1a-4409-a99b-dc3310c786a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done success\n"
          ]
        }
      ],
      "source": [
        "#@markdown #üé≤ Controlnet for SDXL\n",
        "\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/OpenPoseXL2.safetensors -d /content/gladiator_webui/models/controlnet -o OpenPoseXL2.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-canny-rank128.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-canny-rank128.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-canny-rank256.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-canny-rank256.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-depth-rank128.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-depth-rank128.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-depth-rank256.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-depth-rank256.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-recolor-rank128.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-recolor-rank128.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-recolor-rank256.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-recolor-rank256.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-sketch-rank128-metadata.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-sketch-rank128-metadata.safetensors\n",
        "# !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/ckpt/controlnet-sdxl-1.0/resolve/main/control-lora-sketch-rank256.safetensors -d /content/gladiator_webui/models/controlnet -o control-lora-sketch-rank256.safetensors\n",
        "\n",
        "clear_output()\n",
        "print(\"‚úÖ Done\", \"success\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEnR3xY-9Ily",
        "cellView": "form",
        "outputId": "adadb5ae-6630-4fc0-92b1-28190ef9b477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done success\n"
          ]
        }
      ],
      "source": [
        "#@markdown üé≤ Download VAE Collection (+Negtive Embedings)\n",
        "%cd /content/gladiator_webui/models\n",
        "!mkdir -p embeddings/negative\n",
        "%cd /content/gladiator_webui/models/embeddings/negative/\n",
        "!git clone --quiet https://huggingface.co/embed/negative\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "from IPython.display import clear_output\n",
        "\n",
        "VAE = \"sdxl_vae.safetensors\" # @param [\"None\", \"WD-v2.vae.pt\", \"blessed-fix.vae.pt\", \"blessed.vae.pt\", \"blessed2.vae.pt\", \"clearvae_main.safetensors\", \"cute_vae.safetensors\", \"grapefruitVAE_v1.pt\", \"kl-f8-anime.ckpt\", \"kl-f8-anime2.ckpt\", \"nai.vae.pt\", \"orangemix.vae.pt\", \"pastel-waifu-diffusion.vae.pt\", \"rmada-cold-vae.ckpt\", \"vae-ft-mse-840000-ema-pruned.ckpt\", \"vaeextremecolors_v10.pt\", \"sdxl_vae.safetensors\"]\n",
        "\n",
        "VAE_urls = {\n",
        "    \"WD-v2.vae.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/WD-v2.vae.pt',\n",
        "    \"blessed-fix.vae.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/blessed-fix.vae.pt',\n",
        "    \"blessed.vae.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/blessed.vae.pt',\n",
        "    \"blessed2.vae.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/blessed2.vae.pt',\n",
        "    \"clearvae_main.safetensors\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/clearvae_main.safetensors',\n",
        "    \"cute_vae.safetensors\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/cute%20vae.safetensors',\n",
        "    \"grapefruitVAE_v1.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/grapefruitVAE_v1.pt',\n",
        "    \"kl-f8-anime.ckpt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/kl-f8-anime.ckpt',\n",
        "    \"kl-f8-anime2.ckpt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/kl-f8-anime2.ckpt',\n",
        "    \"nai.vae.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/nai.vae.pt',\n",
        "    \"orangemix.vae.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/orangemix.vae.pt',\n",
        "    \"pastel-waifu-diffusion.vae.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/pastel-waifu-diffusion.vae.pt',\n",
        "    \"rmada-cold-vae.ckpt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/rmada-cold-vae.ckpt',\n",
        "    \"vae-ft-mse-840000-ema-pruned.ckpt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt',\n",
        "    \"vaeextremecolors_v10.pt\": 'https://huggingface.co/Kefasu/sd-vae-collection/resolve/main/vaeextremecolors_v10.pt',\n",
        "    \"sdxl_vae.safetensors\": 'https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors'\n",
        "}\n",
        "\n",
        "output_path = \"/content/gladiator_webui/models/VAE/\"\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)  # Create the output directory if it doesn't exist\n",
        "\n",
        "def download_model(model_url, output_path):\n",
        "    filename = os.path.basename(model_url)\n",
        "    output_file = os.path.join(output_path, filename)\n",
        "    urllib.request.urlretrieve(model_url, output_file)\n",
        "    return filename\n",
        "\n",
        "model_url = VAE_urls.get(VAE)\n",
        "if model_url:\n",
        "    download_model(model_url, output_path)\n",
        "    print(\"‚úì Done\", \"success\")\n",
        "else:\n",
        "    clear_output()\n",
        "    print(\"Selected VAE model not found in the list.\")\n",
        "\n",
        "# Clear the output to keep the notebook clean\n",
        "clear_output()\n",
        "print(\"‚úÖ Done\", \"success\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #üé≤Download UPSCALERs\n",
        "\n",
        "# Set the name of the upscaler you want to download here\n",
        "selected_upscaler = \"4x_NMKD-Superscale-SP_178000_G.pth\" # @param [\"None\", \"4x_NMKD-Superscale-SP_178000_G.pth\", \"4x-UltraSharp.pth\", \"4x_CountryRoads_377000_G.pth\", \"4x_Fatality_Comix_260000_G.pth\", \"4x_RealisticRescaler_100000_G.pth\", \"4x_Valar_v1.pth\", \"4x_fatal_Anime_500000_G.pth\", \"4x_foolhardy_Remacri.pth\", \"A_ESRGAN_Single.pth\", \"LADDIER1_282500_G.pth\", \"WaifuGAN_v3_30000.pth\", \"lollypop.pth\", \"sudo_rife4_269.662_testV1_scale1.pth\"]\n",
        "\n",
        "\n",
        "upscalers_urls = {\n",
        "    \"4x_NMKD-Superscale-SP_178000_G.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x_NMKD-Superscale-SP_178000_G.pth',\n",
        "    \"4x-UltraSharp.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x-UltraSharp.pth',\n",
        "    \"4x_CountryRoads_377000_G.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x_CountryRoads_377000_G.pth',\n",
        "    \"4x_Fatality_Comix_260000_G.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x_Fatality_Comix_260000_G.pth',\n",
        "    \"4x_RealisticRescaler_100000_G.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x_RealisticRescaler_100000_G.pth',\n",
        "    \"4x_Valar_v1.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x_Valar_v1.pth',\n",
        "    \"4x_fatal_Anime_500000_G.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x_fatal_Anime_500000_G.pth',\n",
        "    \"4x_foolhardy_Remacri.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/4x_foolhardy_Remacri.pth',\n",
        "    \"A_ESRGAN_Single.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/A_ESRGAN_Single.pth',\n",
        "    \"LADDIER1_282500_G.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/LADDIER1_282500_G.pth',\n",
        "    \"WaifuGAN_v3_30000.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/WaifuGAN_v3_30000.pth',\n",
        "    \"lollypop.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/lollypop.pth',\n",
        "    \"sudo_rife4_269.662_testV1_scale1.pth\": 'https://huggingface.co/uwg/upscaler/resolve/main/ESRGAN/sudo_rife4_269.662_testV1_scale1.pth',\n",
        "}\n",
        "\n",
        "output_path = \"/content/gladiator_webui/models/ESRGAN/\"\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "def download_model(model_url, output_path):\n",
        "    if model_url is None:\n",
        "        return None\n",
        "\n",
        "    filename = os.path.basename(model_url)\n",
        "    output_file = os.path.join(output_path, filename)\n",
        "    urllib.request.urlretrieve(model_url, output_file)\n",
        "    return filename\n",
        "\n",
        "model_url = upscalers_urls.get(selected_upscaler)\n",
        "\n",
        "if model_url is not None:\n",
        "    download_model(model_url, output_path)\n",
        "    print(\"‚úì Done - Success\")\n",
        "else:\n",
        "    clear_output()\n",
        "    print(\"Invalid upscaler selected. Finish...\")\n",
        "\n",
        "clear_output()\n",
        "print(\"‚úÖ Done - Success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Z0ecLKkVpQYu",
        "outputId": "499b7730-64cd-4cfe-8024-7820134c4b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done - Success\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "il4nFMAfu72r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ö°Start Gladiator WebUI"
      ],
      "metadata": {
        "id": "rv5Cc_xkzDEr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚ö°Start Gladiator WebUI\n",
        "\n",
        "# --Function AntiDissconnect\n",
        "%cd /content/gladiator_webui\n",
        "clear_output()\n",
        "audio_url = \"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\"\n",
        "# Function AntiDissconnect in the background\n",
        "def play_audio(url):\n",
        "    display(HTML(f'<audio src=\"{url}\" controls autoplay style=\"display:none\"></audio>'))\n",
        "# Create a separate thread for AntiDissconnect\n",
        "audio_thread = threading.Thread(target=play_audio, args=(audio_url,))\n",
        "audio_thread.start()\n",
        "\n",
        "%env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libjemalloc.so.2\n",
        "%env TF_CPP_MIN_LOG_LEVEL=1\n",
        "\n",
        "!python launch.py --no-half-vae --xformers --enable-insecure-extension-access --ngrok 2NvXfMWtoWSR4BSK0kPINmej7yz_657hrUZX4vbQwVcY2EAKE"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W5w-Suaiy0XX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uwtc9vu8zvj9",
        "uLkmpa1_99LX",
        "rv5Cc_xkzDEr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}